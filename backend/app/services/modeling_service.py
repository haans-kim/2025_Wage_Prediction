import pandas as pd
import numpy as np
from typing import Dict, Any, List, Optional, Tuple
import warnings
import io
import sys
from contextlib import redirect_stdout, redirect_stderr
import logging

# PyCaret ë¼ì´ë¸ŒëŸ¬ë¦¬ import with error handling
try:
    from pycaret.regression import (
        setup, compare_models, create_model, tune_model, 
        finalize_model, predict_model, evaluate_model, 
        pull, get_config
    )
    PYCARET_AVAILABLE = True
except ImportError:
    PYCARET_AVAILABLE = False
    logging.warning("PyCaret not available. Modeling functionality will be limited.")

from app.services.data_service import data_service

class ModelingService:
    def __init__(self):
        self.current_experiment = None
        self.current_model = None
        self.baseup_model = None  # Base-up ì „ìš© ëª¨ë¸
        self.performance_model = None  # ì„±ê³¼ê¸‰ ì „ìš© ëª¨ë¸
        self.model_results = None
        self.is_setup_complete = False
        self.is_model_trained_individually = False  # ê°œë³„ ëª¨ë¸ í•™ìŠµ ì—¬ë¶€
        self.current_target = None  # í˜„ì¬ íƒ€ê²Ÿ ì»¬ëŸ¼
        
        # ë°ì´í„° í¬ê¸°ì— ë”°ë¥¸ ëª¨ë¸ ì„ íƒ
        # PDF ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜ì˜í•˜ì—¬ Random Forestë¥¼ ì†Œê·œëª¨ ë°ì´í„°ì—ë„ í¬í•¨
        self.small_data_models = ['lr', 'ridge', 'lasso', 'en', 'dt', 'rf']
        self.medium_data_models = ['lr', 'ridge', 'lasso', 'en', 'dt', 'rf', 'gbr']
        self.large_data_models = ['lr', 'ridge', 'lasso', 'en', 'dt', 'rf', 'gbr', 'xgboost', 'lightgbm']
    
    def check_pycaret_availability(self) -> bool:
        """PyCaret ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        return PYCARET_AVAILABLE
    
    def get_optimal_settings(self, data_size: int) -> Dict[str, Any]:
        """ë°ì´í„° í¬ê¸°ì— ë”°ë¥¸ ìµœì  ì„¤ì • ë°˜í™˜"""
        if data_size < 30:
            return {
                'train_size': 0.9,
                'cv_folds': 3,
                'models': self.small_data_models,
                'normalize': True,
                'transformation': False,
                'remove_outliers': False,
                'feature_selection': False,
                'n_features_to_select': 0.8
            }
        elif data_size < 100:
            return {
                'train_size': 0.8,
                'cv_folds': 5,
                'models': self.medium_data_models,
                'normalize': True,
                'transformation': True,
                'remove_outliers': True,
                'feature_selection': True,
                'n_features_to_select': 0.7
            }
        else:
            return {
                'train_size': 0.7,
                'cv_folds': 10,
                'models': self.large_data_models,
                'normalize': True,
                'transformation': True,
                'remove_outliers': True,
                'feature_selection': True,
                'n_features_to_select': 0.6
            }
    
    def prepare_data_for_modeling(self, target_column: str) -> Tuple[pd.DataFrame, Dict[str, Any]]:
        """ëª¨ë¸ë§ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„"""
        if data_service.current_data is None:
            raise ValueError("No data loaded for modeling")
        
        df = data_service.current_data.copy()
        
        # ê¸°ë³¸ ë°ì´í„° ì •ë¦¬
        info = {
            'original_shape': df.shape,
            'target_column': target_column,
            'numeric_columns': [],
            'categorical_columns': [],
            'dropped_columns': []
        }
        
        # íƒ€ê²Ÿ ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
        if target_column not in df.columns:
            raise ValueError(f"Target column '{target_column}' not found in data")
        
        # íƒ€ê²Ÿ ì»¬ëŸ¼ì— ê²°ì¸¡ê°’ì´ ìˆëŠ” í–‰ ì œê±° (2025ë…„ ì˜ˆì¸¡ ëŒ€ìƒ ë°ì´í„° ì œì™¸)
        initial_rows = len(df)
        df = df.dropna(subset=[target_column])
        removed_rows = initial_rows - len(df)
        
        if removed_rows > 0:
            info['removed_target_missing'] = removed_rows
            print(f"ğŸ“Š Removed {removed_rows} rows with missing target values (likely future prediction data)")
        
        # íƒ€ê²Ÿ ì»¬ëŸ¼ì´ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        if len(df) < 5:
            raise ValueError(f"Insufficient training data: only {len(df)} rows with valid target values")
        
        # ìµœì†Œí•œì˜ ì „ì²˜ë¦¬ë§Œ ìˆ˜í–‰ (PyCaretì´ ë‚˜ë¨¸ì§€ë¥¼ ì²˜ë¦¬)
        # '-' ê°’ì„ NaNìœ¼ë¡œ ë³€í™˜ (PyCaretì´ ì¸ì‹í•  ìˆ˜ ìˆë„ë¡)
        df = df.replace(['-', ''], np.nan)
        
        # ë²”ì£¼í˜•ìœ¼ë¡œ ë³´ì´ëŠ” ìˆ«ì ì»¬ëŸ¼ì„ ì‹¤ì œ ìˆ«ìë¡œ ë³€í™˜
        for col in df.columns:
            if col != target_column:
                try:
                    # ìˆ«ìë¡œ ë³€í™˜ ê°€ëŠ¥í•œ ì»¬ëŸ¼ì€ ë³€í™˜
                    df[col] = pd.to_numeric(df[col], errors='coerce')
                except:
                    pass
        
        # ë…„ë„ ì»¬ëŸ¼ ì œê±° (ì‹œê³„ì—´ ì¸ë±ìŠ¤ì´ë¯€ë¡œ í”¼ì²˜ì—ì„œ ì œì™¸)
        year_columns = ['year', 'Year', 'YEAR', 'ë…„ë„', 'ì—°ë„']
        for year_col in year_columns:
            if year_col in df.columns and year_col != target_column:
                df = df.drop(columns=[year_col])
                info['dropped_columns'].append(year_col)
                print(f"ğŸ“Š Removed year column: {year_col}")
        
        # íƒ€ê²Ÿ ì»¬ëŸ¼ì´ ìˆ«ìí˜•ì¸ì§€ í™•ì¸
        try:
            df[target_column] = pd.to_numeric(df[target_column], errors='coerce')
            df = df.dropna(subset=[target_column])  # ë³€í™˜ ì‹¤íŒ¨í•œ í–‰ ì œê±°
        except:
            raise ValueError(f"Target column '{target_column}' must contain numeric values")
        
        # PyCaretì´ ëª¨ë“  ì»¬ëŸ¼ì„ ì²˜ë¦¬í•˜ë„ë¡ í•¨
        # ê¸°ë³¸ ì •ë³´ë§Œ ìˆ˜ì§‘
        for col in df.columns:
            if col != target_column:
                if pd.api.types.is_numeric_dtype(df[col]):
                    info['numeric_columns'].append(col)
                else:
                    info['categorical_columns'].append(col)
        
        # ìµœì¢… ì •ë¦¬
        info['final_shape'] = df.shape
        info['feature_count'] = len(df.columns) - 1
        
        return df, info
    
    def setup_pycaret_environment(
        self, 
        target_column: str, 
        train_size: Optional[float] = None,
        session_id: int = 42
    ) -> Dict[str, Any]:
        """PyCaret í™˜ê²½ ì„¤ì •"""
        
        # session_idë¡œ ì¶©ë¶„í•¨ - ì¶”ê°€ seed ì„¤ì • ì œê±°
        
        if not self.check_pycaret_availability():
            raise RuntimeError("PyCaret is not available. Please install it first.")
        
        # ë°ì´í„° ì¤€ë¹„
        ml_data, data_info = self.prepare_data_for_modeling(target_column)
        
        # ìµœì  ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        optimal_settings = self.get_optimal_settings(len(ml_data))
        actual_train_size = train_size or optimal_settings['train_size']
        
        # ì¶œë ¥ ì–µì œë¥¼ ìœ„í•œ ì„¤ì •
        old_stdout = sys.stdout
        old_stderr = sys.stderr
        
        try:
            # ëª¨ë“  ì¶œë ¥ ì–µì œ
            sys.stdout = io.StringIO()
            sys.stderr = io.StringIO()
            
            # PyCaret setup ì‹¤í–‰ (ìë™ ì „ì²˜ë¦¬ ê°•í™”)
            exp = setup(
                data=ml_data,
                target=target_column,
                session_id=session_id,
                train_size=actual_train_size,
                html=False,
                verbose=False,
                
                # ìë™ ë°ì´í„° íƒ€ì… ì¶”ë¡  ë° ì „ì²˜ë¦¬
                numeric_features=None,  # PyCaretì´ ìë™ ê°ì§€
                categorical_features=None,  # PyCaretì´ ìë™ ê°ì§€
                ignore_features=None,
                
                # ê²°ì¸¡ê°’ ì²˜ë¦¬
                imputation_type='simple',  # ë‹¨ìˆœ ëŒ€ì²´
                numeric_imputation='mean',  # ìˆ«ìí˜•: í‰ê· ê°’
                categorical_imputation='mode',  # ë²”ì£¼í˜•: ìµœë¹ˆê°’
                
                # ì ì‘ì  ì „ì²˜ë¦¬ ì˜µì…˜
                normalize=optimal_settings['normalize'],
                transformation=optimal_settings['transformation'],
                remove_outliers=optimal_settings['remove_outliers'],
                remove_multicollinearity=True,
                multicollinearity_threshold=0.9,
                feature_selection=optimal_settings['feature_selection'],
                n_features_to_select=optimal_settings['n_features_to_select'],
                
                # Feature ìƒì„± ì„¤ì •
                polynomial_features=False,  # ë‹¤í•­ì‹ feature ìƒì„± ë¹„í™œì„±í™” (feature ì´ë¦„ ì¶©ëŒ ë°©ì§€)
                polynomial_degree=2,  # ë‹¤í•­ì‹ ì°¨ìˆ˜ (ì‚¬ìš© ì•ˆ í•¨)
                
                # CV ì „ëµ
                fold_strategy='kfold',
                fold=optimal_settings['cv_folds']
            )
            
            self.current_experiment = exp
            self.is_setup_complete = True
            self.current_target = target_column  # í˜„ì¬ íƒ€ê²Ÿ ì €ì¥
            
        except Exception as e:
            raise RuntimeError(f"PyCaret setup failed: {str(e)}")
        finally:
            # ì¶œë ¥ ë³µì›
            sys.stdout = old_stdout
            sys.stderr = old_stderr
        
        # ì„¤ì • ì •ë³´ ë°˜í™˜
        return {
            'message': 'PyCaret environment setup completed successfully',
            'data_info': data_info,
            'optimal_settings': optimal_settings,
            'train_size': actual_train_size,
            'available_models': optimal_settings['models']
        }
    
    def compare_models_adaptive(self, n_select: int = 3) -> Dict[str, Any]:
        """ë°ì´í„° í¬ê¸°ì— ì ì‘ì ì¸ ëª¨ë¸ ë¹„êµ"""
        
        if not self.is_setup_complete:
            raise RuntimeError("PyCaret environment not setup. Call setup_pycaret_environment first.")
        
        # PyCaretì´ ìì²´ì ìœ¼ë¡œ seedë¥¼ ê´€ë¦¬í•˜ë„ë¡ í•¨
        
        # í˜„ì¬ ë°ì´í„° í¬ê¸° í™•ì¸
        data_size = len(data_service.current_data)
        optimal_settings = self.get_optimal_settings(data_size)
        models_to_use = optimal_settings['models']
        
        old_stdout = sys.stdout
        old_stderr = sys.stderr
        
        try:
            # ì¶œë ¥ ì–µì œ
            sys.stdout = io.StringIO()
            sys.stderr = io.StringIO()
            
            # ëª¨ë¸ ë¹„êµ ì‹¤í–‰
            # ì‘ì€ ë°ì´í„°ì…‹ì—ì„œëŠ” MAEê°€ ë” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì§€í‘œ
            best_models = compare_models(
                include=models_to_use,
                sort='MAE',  # MAEê°€ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ (R2ëŠ” ìŒìˆ˜ê°€ ë‚˜ì˜¬ ìˆ˜ ìˆìŒ)
                n_select=min(n_select, len(models_to_use)),
                verbose=False,
                fold=3  # ë¹ ë¥¸ ë¹„êµë¥¼ ìœ„í•´ fold ìˆ˜ ì œí•œ
            )
            
            # ë‹¨ì¼ ëª¨ë¸ì´ ë°˜í™˜ëœ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            if not isinstance(best_models, list):
                best_models = [best_models]
            
            # ê²°ê³¼ ì •ë³´ ì¶”ì¶œ
            comparison_results = pull()
            
            self.model_results = {
                'best_models': best_models,
                'comparison_df': comparison_results,
                'recommended_model': best_models[0] if best_models else None
            }
            
            # current_model ì„¤ì •
            self.current_model = best_models[0] if best_models else None
            
            # íƒ€ê²Ÿì— ë”°ë¥¸ ëª¨ë¸ ì €ì¥
            if self.current_target == 'wage_increase_bu_sbl':
                self.baseup_model = self.current_model
                print(f"âœ… Base-up model saved: {type(self.current_model).__name__}")
            elif self.current_target == 'wage_increase_mi_sbl':
                self.performance_model = self.current_model
                print(f"âœ… Performance model saved: {type(self.current_model).__name__}")
            
        except Exception as e:
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì„ í˜• íšŒê·€ ì‚¬ìš©
            warnings.warn(f"Model comparison failed: {str(e)}. Using default linear regression.")
            
            linear_model = create_model('lr', verbose=False)
            self.model_results = {
                'best_models': [linear_model],
                'comparison_df': None,
                'recommended_model': linear_model,
                'fallback_used': True
            }
            self.current_model = linear_model
            
        finally:
            # ì¶œë ¥ ë³µì›
            sys.stdout = old_stdout
            sys.stderr = old_stderr
        
        # comparison_dfë¥¼ JSONìœ¼ë¡œ ë³€í™˜
        comparison_results = []
        if self.model_results['comparison_df'] is not None:
            df = self.model_results['comparison_df']
            for idx, row in df.iterrows():
                comparison_results.append({
                    'Model': idx if isinstance(idx, str) else str(idx),
                    'MAE': float(row.get('MAE', 0)) if 'MAE' in row else None,
                    'MSE': float(row.get('MSE', 0)) if 'MSE' in row else None,
                    'RMSE': float(row.get('RMSE', 0)) if 'RMSE' in row else None,
                    'R2': float(row.get('R2', 0)) if 'R2' in row else None,
                    'RMSLE': float(row.get('RMSLE', 0)) if 'RMSLE' in row else None,
                    'MAPE': float(row.get('MAPE', 0)) if 'MAPE' in row else None
                })
        
        return {
            'message': 'Model comparison completed',
            'models_compared': len(models_to_use),
            'best_model_count': len(self.model_results['best_models']),
            'recommended_model_type': type(self.model_results['recommended_model']).__name__,
            'comparison_available': self.model_results['comparison_df'] is not None,
            'comparison_results': comparison_results,
            'data_size_category': 'small' if data_size < 30 else 'medium' if data_size < 100 else 'large'
        }
    
    def train_specific_model(self, model_name: str) -> Dict[str, Any]:
        """íŠ¹ì • ëª¨ë¸ í•™ìŠµ"""
        
        if not self.is_setup_complete:
            raise RuntimeError("PyCaret environment not setup. Call setup_pycaret_environment first.")
        
        # PyCaretì´ ìì²´ì ìœ¼ë¡œ seedë¥¼ ê´€ë¦¬í•˜ë„ë¡ í•¨
        
        old_stdout = sys.stdout
        old_stderr = sys.stderr
        
        try:
            # ì¶œë ¥ ì–µì œ
            sys.stdout = io.StringIO()
            sys.stderr = io.StringIO()
            
            # ëª¨ë¸ ìƒì„±
            model = create_model(model_name, verbose=False)
            
            # ëª¨ë¸ íŠœë‹ (ì„ íƒì )
            try:
                tuned_model = tune_model(model, optimize='R2', verbose=False)
            except:
                tuned_model = model
            
            # ìµœì¢… ëª¨ë¸
            try:
                final_model = finalize_model(tuned_model)
            except:
                final_model = tuned_model
            
            self.current_model = final_model
            self.is_model_trained_individually = True  # ê°œë³„ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ
            
            # íƒ€ê²Ÿì— ë”°ë¼ ëª¨ë¸ ì €ì¥
            if self.current_target == 'wage_increase_bu_sbl':
                self.baseup_model = final_model
                logging.info("Base-up model stored")
            elif self.current_target == 'wage_increase_mi_sbl':
                self.performance_model = final_model
                logging.info("Performance model stored")
            
            # ëª¨ë¸ í‰ê°€ ë©”íŠ¸ë¦­ ê°€ì ¸ì˜¤ê¸°
            try:
                # í˜„ì¬ ëª¨ë¸ì˜ ì„±ëŠ¥ í‰ê°€
                from pycaret.regression import predict_model, pull
                predictions = predict_model(final_model, verbose=False)
                metrics = pull()
                
                # ë©”íŠ¸ë¦­ ì¶”ì¶œ
                model_metrics = {}
                if metrics is not None and not metrics.empty:
                    if 'MAE' in metrics.columns:
                        model_metrics['MAE'] = float(metrics['MAE'].iloc[-1])
                    if 'MSE' in metrics.columns:
                        model_metrics['MSE'] = float(metrics['MSE'].iloc[-1])
                    if 'RMSE' in metrics.columns:
                        model_metrics['RMSE'] = float(metrics['RMSE'].iloc[-1])
                    if 'R2' in metrics.columns:
                        model_metrics['R2'] = float(metrics['R2'].iloc[-1])
                    if 'RMSLE' in metrics.columns:
                        model_metrics['RMSLE'] = float(metrics['RMSLE'].iloc[-1])
                    if 'MAPE' in metrics.columns:
                        model_metrics['MAPE'] = float(metrics['MAPE'].iloc[-1])
            except:
                model_metrics = {}
            
        except Exception as e:
            raise RuntimeError(f"Model training failed: {str(e)}")
        finally:
            # ì¶œë ¥ ë³µì›
            sys.stdout = old_stdout
            sys.stderr = old_stderr
        
        return {
            'message': f'Model {model_name} trained successfully',
            'model_type': type(self.current_model).__name__,
            'model_name': model_name,
            'metrics': model_metrics if model_metrics else None
        }
    
    def get_model_evaluation(self) -> Dict[str, Any]:
        """í˜„ì¬ ëª¨ë¸ì˜ í‰ê°€ ê²°ê³¼ ë°˜í™˜"""
        
        if self.current_model is None:
            if self.model_results and self.model_results['recommended_model']:
                self.current_model = self.model_results['recommended_model']
            else:
                raise RuntimeError("No trained model available")
        
        old_stdout = sys.stdout
        old_stderr = sys.stderr
        
        try:
            # ì¶œë ¥ ì–µì œ
            sys.stdout = io.StringIO()
            sys.stderr = io.StringIO()
            
            # ëª¨ë¸ í‰ê°€
            evaluate_model(self.current_model)
            evaluation_results = pull()
            
        except Exception as e:
            # í‰ê°€ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì •ë³´ë§Œ ë°˜í™˜
            evaluation_results = None
            warnings.warn(f"Model evaluation failed: {str(e)}")
        finally:
            # ì¶œë ¥ ë³µì›
            sys.stdout = old_stdout
            sys.stderr = old_stderr
        
        return {
            'message': 'Model evaluation completed',
            'model_type': type(self.current_model).__name__,
            'evaluation_available': evaluation_results is not None,
            'evaluation_data': evaluation_results.to_dict() if evaluation_results is not None else None
        }
    
    def predict_with_model(self, prediction_data: Optional[pd.DataFrame] = None) -> Dict[str, Any]:
        """ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ ìˆ˜í–‰"""
        
        if self.current_model is None:
            raise RuntimeError("No trained model available for prediction")
        
        if prediction_data is None:
            # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì˜ˆì¸¡
            try:
                old_stdout = sys.stdout
                sys.stdout = io.StringIO()
                
                predictions = predict_model(self.current_model)
                prediction_results = pull()
                
            except Exception as e:
                raise RuntimeError(f"Prediction failed: {str(e)}")
            finally:
                sys.stdout = old_stdout
        else:
            # ì‚¬ìš©ì ì œê³µ ë°ì´í„°ë¡œ ì˜ˆì¸¡
            try:
                old_stdout = sys.stdout
                old_stderr = sys.stderr
                sys.stdout = io.StringIO()
                sys.stderr = io.StringIO()
                
                # PyCaretì˜ TransformerWrapperë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€í™˜ íŒŒì´í”„ë¼ì¸ ê°€ì ¸ì˜¤ê¸°
                try:
                    # get_configë¥¼ ì‚¬ìš©í•˜ì—¬ í˜„ì¬ ì‹¤í—˜ì˜ ë³€í™˜ íŒŒì´í”„ë¼ì¸ ê°€ì ¸ì˜¤ê¸°
                    X_train = get_config('X_train')
                    
                    # í•™ìŠµ ì‹œ ì‚¬ìš©ëœ feature ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
                    if hasattr(X_train, 'columns'):
                        expected_features = X_train.columns.tolist()
                    else:
                        expected_features = None
                    
                    # prediction_dataì˜ ì»¬ëŸ¼ì„ í•™ìŠµ ì‹œ ì‚¬ìš©ëœ featureì— ë§ê²Œ ì¡°ì •
                    if expected_features:
                        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ê³  ìˆœì„œ ë§ì¶”ê¸°
                        available_cols = [col for col in expected_features if col in prediction_data.columns]
                        prediction_data_aligned = prediction_data[available_cols].copy()
                        
                        # ëˆ„ë½ëœ ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ 0ìœ¼ë¡œ ì±„ìš°ê¸° (polynomial features ë“±)
                        for col in expected_features:
                            if col not in prediction_data_aligned.columns:
                                prediction_data_aligned[col] = 0
                        
                        # ì»¬ëŸ¼ ìˆœì„œ ë§ì¶”ê¸°
                        prediction_data_aligned = prediction_data_aligned[expected_features]
                    else:
                        prediction_data_aligned = prediction_data
                    
                    predictions = predict_model(self.current_model, data=prediction_data_aligned)
                    
                except Exception as align_error:
                    # ì •ë ¬ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°ì´í„°ë¡œ ì˜ˆì¸¡ ì‹œë„
                    warnings.warn(f"Feature alignment failed: {str(align_error)}. Trying with original data.")
                    predictions = predict_model(self.current_model, data=prediction_data)
                
            except Exception as e:
                raise RuntimeError(f"Prediction with custom data failed: {str(e)}")
            finally:
                sys.stdout = old_stdout
                sys.stderr = old_stderr
            
            prediction_results = None
        
        return {
            'message': 'Prediction completed successfully',
            'predictions_available': predictions is not None,
            'prediction_count': len(predictions) if predictions is not None else 0,
            'predictions': predictions.to_dict(orient='records') if predictions is not None else None,
            'evaluation_metrics': prediction_results.to_dict() if prediction_results is not None else None
        }
    
    def get_modeling_status(self) -> Dict[str, Any]:
        """í˜„ì¬ ëª¨ë¸ë§ ìƒíƒœ ë°˜í™˜"""
        return {
            'pycaret_available': self.check_pycaret_availability(),
            'environment_setup': self.is_setup_complete,
            'model_trained': self.is_model_trained_individually,  # ê°œë³„ í•™ìŠµ ì—¬ë¶€ë¡œ ë³€ê²½
            'models_compared': self.model_results is not None,
            'data_loaded': data_service.current_data is not None,
            'current_model_type': type(self.current_model).__name__ if self.current_model else None,
            'has_model': self.current_model is not None  # ëª¨ë¸ ì¡´ì¬ ì—¬ë¶€
        }
    
    def clear_models(self) -> Dict[str, Any]:
        """ëª¨ë“  ëª¨ë¸ ë° ì‹¤í—˜ ì´ˆê¸°í™”"""
        self.current_experiment = None
        self.current_model = None
        self.model_results = None
        self.is_setup_complete = False
        self.is_model_trained_individually = False  # ê°œë³„ í•™ìŠµ ìƒíƒœë„ ì´ˆê¸°í™”
        
        return {
            'message': 'All models and experiments cleared successfully'
        }

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
modeling_service = ModelingService()