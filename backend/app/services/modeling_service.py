import pandas as pd
import numpy as np
from typing import Dict, Any, List, Optional, Tuple
import warnings
import io
import sys
import os
import pickle
from contextlib import redirect_stdout, redirect_stderr
import logging

# PyCaret ë¼ì´ë¸ŒëŸ¬ë¦¬ import with error handling
try:
    from pycaret.regression import (
        setup, compare_models, create_model, tune_model, 
        finalize_model, predict_model, evaluate_model, 
        pull, get_config
    )
    PYCARET_AVAILABLE = True
except ImportError:
    PYCARET_AVAILABLE = False
    logging.warning("PyCaret not available. Modeling functionality will be limited.")

from app.services.data_service import data_service

class ModelingService:
    def __init__(self):
        self.current_experiment = None
        self.current_model = None
        self.baseup_model = None  # Base-up ì „ìš© ëª¨ë¸
        self.performance_model = None  # ì„±ê³¼ê¸‰ ì „ìš© ëª¨ë¸
        self.model_results = None
        self.is_setup_complete = False
        self.is_model_trained_individually = False  # ê°œë³„ ëª¨ë¸ í•™ìŠµ ì—¬ë¶€
        self.current_target = None  # í˜„ì¬ íƒ€ê²Ÿ ì»¬ëŸ¼
        
        # Feature importance ì €ì¥
        self.baseup_feature_importance = None
        self.performance_feature_importance = None
        self.current_feature_importance = None
        
        # ë°ì´í„° í¬ê¸°ì— ë”°ë¥¸ ëª¨ë¸ ì„ íƒ
        # PDF ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜ì˜í•˜ì—¬ Random Forestë¥¼ ì†Œê·œëª¨ ë°ì´í„°ì—ë„ í¬í•¨
        # Lasso ì œì™¸ (ì ì€ ë°ì´í„°ì—ì„œ ëª¨ë“  ê³„ìˆ˜ë¥¼ 0ìœ¼ë¡œ ë§Œë“œëŠ” ë¬¸ì œ ë°©ì§€)
        self.small_data_models = ['lr', 'ridge', 'en', 'dt', 'rf']  # lasso ì œì™¸
        self.medium_data_models = ['lr', 'ridge', 'en', 'dt', 'rf', 'gbr']  # lasso ì œì™¸
        self.large_data_models = ['lr', 'ridge', 'en', 'dt', 'rf', 'gbr', 'xgboost', 'lightgbm']  # lasso ì œì™¸
        
        # ëª¨ë¸ ì €ì¥ ê²½ë¡œ
        self.model_dir = "saved_models"
        self.baseup_model_path = os.path.join(self.model_dir, "baseup_model.pkl")
        self.performance_model_path = os.path.join(self.model_dir, "performance_model.pkl")
        
        # ì„œë²„ ì‹œì‘ ì‹œ ì €ì¥ëœ ëª¨ë¸ ìë™ ë¡œë“œ
        print("\n" + "=" * 80)
        print("ğŸš€ INITIALIZING MODEL SERVICE")
        print("=" * 80)
        self.load_saved_models()
        print("=" * 80 + "\n")
    
    def check_pycaret_availability(self) -> bool:
        """PyCaret ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        return PYCARET_AVAILABLE
    
    def get_optimal_settings(self, data_size: int) -> Dict[str, Any]:
        """ë°ì´í„° í¬ê¸°ì— ë”°ë¥¸ ìµœì  ì„¤ì • ë°˜í™˜"""
        if data_size < 30:
            return {
                'train_size': 0.9,
                'cv_folds': 3,
                'models': self.small_data_models,
                'normalize': True,
                'transformation': False,
                'remove_outliers': False,
                'feature_selection': False,
                'n_features_to_select': 0.8
            }
        elif data_size < 100:
            return {
                'train_size': 0.8,
                'cv_folds': 5,
                'models': self.medium_data_models,
                'normalize': True,
                'transformation': True,
                'remove_outliers': True,
                'feature_selection': True,
                'n_features_to_select': 0.7
            }
        else:
            return {
                'train_size': 0.7,
                'cv_folds': 10,
                'models': self.large_data_models,
                'normalize': True,
                'transformation': True,
                'remove_outliers': True,
                'feature_selection': True,
                'n_features_to_select': 0.6
            }
    
    def prepare_data_for_modeling(self, target_column: str) -> Tuple[pd.DataFrame, Dict[str, Any]]:
        """ëª¨ë¸ë§ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„"""
        if data_service.current_data is None:
            raise ValueError("No data loaded for modeling")
        
        df = data_service.current_data.copy()
        
        # ê¸°ë³¸ ë°ì´í„° ì •ë¦¬
        info = {
            'original_shape': df.shape,
            'target_column': target_column,
            'numeric_columns': [],
            'categorical_columns': [],
            'dropped_columns': []
        }
        
        # íƒ€ê²Ÿ ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
        if target_column not in df.columns:
            raise ValueError(f"Target column '{target_column}' not found in data")
        
        # íƒ€ê²Ÿ ì»¬ëŸ¼ì— ê²°ì¸¡ê°’ì´ ìˆëŠ” í–‰ ì œê±° (2025ë…„ ì˜ˆì¸¡ ëŒ€ìƒ ë°ì´í„° ì œì™¸)
        initial_rows = len(df)
        df = df.dropna(subset=[target_column])
        removed_rows = initial_rows - len(df)
        
        if removed_rows > 0:
            info['removed_target_missing'] = removed_rows
            print(f"ğŸ“Š Removed {removed_rows} rows with missing target values (likely future prediction data)")
        
        # íƒ€ê²Ÿ ì»¬ëŸ¼ì´ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        if len(df) < 5:
            raise ValueError(f"Insufficient training data: only {len(df)} rows with valid target values")
        
        # ìµœì†Œí•œì˜ ì „ì²˜ë¦¬ë§Œ ìˆ˜í–‰ (PyCaretì´ ë‚˜ë¨¸ì§€ë¥¼ ì²˜ë¦¬)
        # '-' ê°’ì„ NaNìœ¼ë¡œ ë³€í™˜ (PyCaretì´ ì¸ì‹í•  ìˆ˜ ìˆë„ë¡)
        df = df.replace(['-', ''], np.nan)
        
        # ë²”ì£¼í˜•ìœ¼ë¡œ ë³´ì´ëŠ” ìˆ«ì ì»¬ëŸ¼ì„ ì‹¤ì œ ìˆ«ìë¡œ ë³€í™˜
        for col in df.columns:
            if col != target_column:
                try:
                    # ìˆ«ìë¡œ ë³€í™˜ ê°€ëŠ¥í•œ ì»¬ëŸ¼ì€ ë³€í™˜
                    df[col] = pd.to_numeric(df[col], errors='coerce')
                except:
                    pass
        
        # ë…„ë„ ì»¬ëŸ¼ ì œê±° (ì‹œê³„ì—´ ì¸ë±ìŠ¤ì´ë¯€ë¡œ í”¼ì²˜ì—ì„œ ì œì™¸)
        year_columns = ['year', 'Year', 'YEAR', 'ë…„ë„', 'ì—°ë„']
        for year_col in year_columns:
            if year_col in df.columns and year_col != target_column:
                df = df.drop(columns=[year_col])
                info['dropped_columns'].append(year_col)
                print(f"ğŸ“Š Removed year column: {year_col}")
        
        # íƒ€ê²Ÿ ì»¬ëŸ¼ì´ ìˆ«ìí˜•ì¸ì§€ í™•ì¸
        try:
            df[target_column] = pd.to_numeric(df[target_column], errors='coerce')
            df = df.dropna(subset=[target_column])  # ë³€í™˜ ì‹¤íŒ¨í•œ í–‰ ì œê±°
        except:
            raise ValueError(f"Target column '{target_column}' must contain numeric values")
        
        # PyCaretì´ ëª¨ë“  ì»¬ëŸ¼ì„ ì²˜ë¦¬í•˜ë„ë¡ í•¨
        # ê¸°ë³¸ ì •ë³´ë§Œ ìˆ˜ì§‘
        for col in df.columns:
            if col != target_column:
                if pd.api.types.is_numeric_dtype(df[col]):
                    info['numeric_columns'].append(col)
                else:
                    info['categorical_columns'].append(col)
        
        # ìµœì¢… ì •ë¦¬
        info['final_shape'] = df.shape
        info['feature_count'] = len(df.columns) - 1
        
        return df, info
    
    def setup_pycaret_environment(
        self, 
        target_column: str, 
        train_size: Optional[float] = None,
        session_id: int = 42
    ) -> Dict[str, Any]:
        """PyCaret í™˜ê²½ ì„¤ì •"""
        
        # session_idë¡œ ì¶©ë¶„í•¨ - ì¶”ê°€ seed ì„¤ì • ì œê±°
        
        if not self.check_pycaret_availability():
            raise RuntimeError("PyCaret is not available. Please install it first.")
        
        # ë°ì´í„° ì¤€ë¹„
        ml_data, data_info = self.prepare_data_for_modeling(target_column)
        
        # ìµœì  ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        optimal_settings = self.get_optimal_settings(len(ml_data))
        actual_train_size = train_size or optimal_settings['train_size']
        
        # ì¶œë ¥ ì–µì œë¥¼ ìœ„í•œ ì„¤ì •
        old_stdout = sys.stdout
        old_stderr = sys.stderr
        
        try:
            # ëª¨ë“  ì¶œë ¥ ì–µì œ
            sys.stdout = io.StringIO()
            sys.stderr = io.StringIO()
            
            # PyCaret setup ì‹¤í–‰ (ìë™ ì „ì²˜ë¦¬ ê°•í™”)
            exp = setup(
                data=ml_data,
                target=target_column,
                session_id=session_id,
                train_size=actual_train_size,
                html=False,
                verbose=False,
                
                # ìë™ ë°ì´í„° íƒ€ì… ì¶”ë¡  ë° ì „ì²˜ë¦¬
                numeric_features=None,  # PyCaretì´ ìë™ ê°ì§€
                categorical_features=None,  # PyCaretì´ ìë™ ê°ì§€
                ignore_features=None,
                
                # ê²°ì¸¡ê°’ ì²˜ë¦¬
                imputation_type='simple',  # ë‹¨ìˆœ ëŒ€ì²´
                numeric_imputation='mean',  # ìˆ«ìí˜•: í‰ê· ê°’
                categorical_imputation='mode',  # ë²”ì£¼í˜•: ìµœë¹ˆê°’
                
                # ì ì‘ì  ì „ì²˜ë¦¬ ì˜µì…˜
                normalize=optimal_settings['normalize'],
                transformation=optimal_settings['transformation'],
                remove_outliers=optimal_settings['remove_outliers'],
                remove_multicollinearity=True,
                multicollinearity_threshold=0.9,
                feature_selection=optimal_settings['feature_selection'],
                n_features_to_select=optimal_settings['n_features_to_select'],
                
                # Feature ìƒì„± ì„¤ì •
                polynomial_features=False,  # ë‹¤í•­ì‹ feature ìƒì„± ë¹„í™œì„±í™” (feature ì´ë¦„ ì¶©ëŒ ë°©ì§€)
                polynomial_degree=2,  # ë‹¤í•­ì‹ ì°¨ìˆ˜ (ì‚¬ìš© ì•ˆ í•¨)
                
                # CV ì „ëµ
                fold_strategy='kfold',
                fold=optimal_settings['cv_folds']
            )
            
            self.current_experiment = exp
            self.is_setup_complete = True
            self.current_target = target_column  # í˜„ì¬ íƒ€ê²Ÿ ì €ì¥
            
        except Exception as e:
            raise RuntimeError(f"PyCaret setup failed: {str(e)}")
        finally:
            # ì¶œë ¥ ë³µì›
            sys.stdout = old_stdout
            sys.stderr = old_stderr
        
        # ì„¤ì • ì •ë³´ ë°˜í™˜
        return {
            'message': 'PyCaret environment setup completed successfully',
            'data_info': data_info,
            'optimal_settings': optimal_settings,
            'train_size': actual_train_size,
            'available_models': optimal_settings['models']
        }
    
    def compare_models_adaptive(self, n_select: int = 3) -> Dict[str, Any]:
        """ë°ì´í„° í¬ê¸°ì— ì ì‘ì ì¸ ëª¨ë¸ ë¹„êµ"""
        
        if not self.is_setup_complete:
            raise RuntimeError("PyCaret environment not setup. Call setup_pycaret_environment first.")
        
        # PyCaretì´ ìì²´ì ìœ¼ë¡œ seedë¥¼ ê´€ë¦¬í•˜ë„ë¡ í•¨
        
        # í˜„ì¬ ë°ì´í„° í¬ê¸° í™•ì¸
        data_size = len(data_service.current_data)
        optimal_settings = self.get_optimal_settings(data_size)
        models_to_use = optimal_settings['models']
        
        old_stdout = sys.stdout
        old_stderr = sys.stderr
        
        # ë””ë²„ê¹… ì¶œë ¥ (stdout ì–µì œ ì „ì—)
        print(f"ğŸ“Š Comparing models: {models_to_use}")
        print(f"ğŸ“Š Current target: {self.current_target}")
        
        try:
            # ì¶œë ¥ ì–µì œ
            sys.stdout = io.StringIO()
            sys.stderr = io.StringIO()
            
            # ëª¨ë¸ ë¹„êµ ì‹¤í–‰
            # ì‘ì€ ë°ì´í„°ì…‹ì—ì„œëŠ” MAEê°€ ë” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì§€í‘œ
            best_models = compare_models(
                include=models_to_use,
                sort='MAE',  # MAEê°€ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ (R2ëŠ” ìŒìˆ˜ê°€ ë‚˜ì˜¬ ìˆ˜ ìˆìŒ)
                n_select=min(n_select, len(models_to_use)),
                verbose=False,
                fold=3  # ë¹ ë¥¸ ë¹„êµë¥¼ ìœ„í•´ fold ìˆ˜ ì œí•œ
            )
            
            # ë‹¨ì¼ ëª¨ë¸ì´ ë°˜í™˜ëœ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            if not isinstance(best_models, list):
                best_models = [best_models]
            
            # ê²°ê³¼ ì •ë³´ ì¶”ì¶œ
            comparison_results = pull()
            
            # stdout ë³µì› í›„ ë””ë²„ê¹… ì¶œë ¥
            sys.stdout = old_stdout
            sys.stderr = old_stderr
            print(f"ğŸ“Š Pull results shape: {comparison_results.shape if hasattr(comparison_results, 'shape') else 'N/A'}")
            print(f"ğŸ“Š Pull results columns: {list(comparison_results.columns) if hasattr(comparison_results, 'columns') else 'N/A'}")
            if not comparison_results.empty:
                print(f"ğŸ“Š Top model from pull: {comparison_results.index[0]}")
            
            # ë‹¤ì‹œ ì–µì œ
            sys.stdout = io.StringIO()
            sys.stderr = io.StringIO()
            
            self.model_results = {
                'best_models': best_models,
                'comparison_df': comparison_results,
                'recommended_model': best_models[0] if best_models else None
            }
            
            # current_model ì„¤ì •
            self.current_model = best_models[0] if best_models else None
            
            # Feature importance ìº¡ì²˜
            if self.current_model:
                feature_importance = self._capture_feature_importance(self.current_model)
                self.current_feature_importance = feature_importance
            else:
                feature_importance = None
            
            # íƒ€ê²Ÿì— ë”°ë¥¸ ëª¨ë¸ ë° feature importance ì €ì¥
            if self.current_target == 'wage_increase_bu_sbl':
                self.baseup_model = self.current_model
                self.baseup_feature_importance = feature_importance
                print(f"âœ… Base-up model saved: {type(self.current_model).__name__} with {len(feature_importance) if feature_importance else 0} features")
            elif self.current_target == 'wage_increase_mi_sbl':
                self.performance_model = self.current_model
                self.performance_feature_importance = feature_importance
                print(f"âœ… Performance model saved: {type(self.current_model).__name__} with {len(feature_importance) if feature_importance else 0} features")
            
        except Exception as e:
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì„ í˜• íšŒê·€ ì‚¬ìš©
            warnings.warn(f"Model comparison failed: {str(e)}. Using default linear regression.")
            
            linear_model = create_model('lr', verbose=False)
            self.model_results = {
                'best_models': [linear_model],
                'comparison_df': None,
                'recommended_model': linear_model,
                'fallback_used': True
            }
            self.current_model = linear_model
            
        finally:
            # ì¶œë ¥ ë³µì›
            sys.stdout = old_stdout
            sys.stderr = old_stderr
        
        # comparison_dfë¥¼ JSONìœ¼ë¡œ ë³€í™˜
        comparison_results = []
        if self.model_results['comparison_df'] is not None:
            df = self.model_results['comparison_df']
            # Model ì—´ì´ ìˆëŠ” ê²½ìš° ì‚¬ìš©, ì—†ìœ¼ë©´ ì¸ë±ìŠ¤ ì‚¬ìš©
            if 'Model' in df.columns:
                for _, row in df.iterrows():
                    comparison_results.append({
                        'Model': str(row['Model']),
                        'MAE': float(row.get('MAE', 0)) if 'MAE' in row else None,
                        'MSE': float(row.get('MSE', 0)) if 'MSE' in row else None,
                        'RMSE': float(row.get('RMSE', 0)) if 'RMSE' in row else None,
                        'R2': float(row.get('R2', 0)) if 'R2' in row else None,
                        'RMSLE': float(row.get('RMSLE', 0)) if 'RMSLE' in row else None,
                        'MAPE': float(row.get('MAPE', 0)) if 'MAPE' in row else None
                    })
            else:
                # Model ì—´ì´ ì—†ìœ¼ë©´ ì¸ë±ìŠ¤ë¥¼ ëª¨ë¸ëª…ìœ¼ë¡œ ì‚¬ìš©
                for idx, row in df.iterrows():
                    comparison_results.append({
                        'Model': idx if isinstance(idx, str) else str(idx),
                        'MAE': float(row.get('MAE', 0)) if 'MAE' in row else None,
                        'MSE': float(row.get('MSE', 0)) if 'MSE' in row else None,
                        'RMSE': float(row.get('RMSE', 0)) if 'RMSE' in row else None,
                        'R2': float(row.get('R2', 0)) if 'R2' in row else None,
                        'RMSLE': float(row.get('RMSLE', 0)) if 'RMSLE' in row else None,
                        'MAPE': float(row.get('MAPE', 0)) if 'MAPE' in row else None
                    })
        
        return {
            'message': 'Model comparison completed',
            'models_compared': len(models_to_use),
            'best_model_count': len(self.model_results['best_models']),
            'recommended_model_type': type(self.model_results['recommended_model']).__name__,
            'comparison_available': self.model_results['comparison_df'] is not None,
            'comparison_results': comparison_results,
            'data_size_category': 'small' if data_size < 30 else 'medium' if data_size < 100 else 'large'
        }
    
    def train_specific_model(self, model_name: str) -> Dict[str, Any]:
        """íŠ¹ì • ëª¨ë¸ í•™ìŠµ"""
        
        if not self.is_setup_complete:
            raise RuntimeError("PyCaret environment not setup. Call setup_pycaret_environment first.")
        
        # ëª¨ë¸ ì´ë¦„ ë§¤í•‘ (ì „ì²´ ì´ë¦„ -> ì½”ë“œ)
        model_name_map = {
            'Linear Regression': 'lr',
            'Ridge Regression': 'ridge',
            'Lasso Regression': 'lasso',
            'Elastic Net': 'en',
            'Decision Tree Regressor': 'dt',
            'Random Forest Regressor': 'rf',
            'Gradient Boosting Regressor': 'gbr',
            'XGBoost Regressor': 'xgboost',
            'Light Gradient Boosting Machine': 'lightgbm',
            # ì½”ë“œë„ ê·¸ëŒ€ë¡œ ë°›ì„ ìˆ˜ ìˆë„ë¡
            'lr': 'lr',
            'ridge': 'ridge',
            'lasso': 'lasso',
            'en': 'en',
            'dt': 'dt',
            'rf': 'rf',
            'gbr': 'gbr',
            'xgboost': 'xgboost',
            'lightgbm': 'lightgbm'
        }
        
        # ëª¨ë¸ ì´ë¦„ì„ ì½”ë“œë¡œ ë³€í™˜
        model_code = model_name_map.get(model_name, model_name.lower())
        print(f"ğŸ“Š Training model: {model_name} -> {model_code}")
        
        # PyCaretì´ ìì²´ì ìœ¼ë¡œ seedë¥¼ ê´€ë¦¬í•˜ë„ë¡ í•¨
        
        old_stdout = sys.stdout
        old_stderr = sys.stderr
        
        try:
            # ì¶œë ¥ ì–µì œ
            sys.stdout = io.StringIO()
            sys.stderr = io.StringIO()
            
            # ëª¨ë¸ ìƒì„±
            model = create_model(model_code, verbose=False)
            
            # ëª¨ë¸ íŠœë‹ (ì„ íƒì )
            try:
                tuned_model = tune_model(model, optimize='R2', verbose=False)
            except:
                tuned_model = model
            
            # ìµœì¢… ëª¨ë¸
            try:
                final_model = finalize_model(tuned_model)
            except:
                final_model = tuned_model
            
            self.current_model = final_model
            self.is_model_trained_individually = True  # ê°œë³„ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ
            
            # Feature importance ìº¡ì²˜
            feature_importance = self._capture_feature_importance(final_model)
            
            # íƒ€ê²Ÿì— ë”°ë¼ ëª¨ë¸ ë° feature importance ì €ì¥
            if self.current_target == 'wage_increase_bu_sbl':
                self.baseup_model = final_model
                self.baseup_feature_importance = feature_importance
                logging.info(f"Base-up model stored with {len(feature_importance) if feature_importance else 0} features")
            elif self.current_target == 'wage_increase_mi_sbl':
                self.performance_model = final_model
                self.performance_feature_importance = feature_importance
                logging.info(f"Performance model stored with {len(feature_importance) if feature_importance else 0} features")
            
            self.current_feature_importance = feature_importance
            
            # ëª¨ë¸ í‰ê°€ ë©”íŠ¸ë¦­ ê°€ì ¸ì˜¤ê¸°
            try:
                # í˜„ì¬ ëª¨ë¸ì˜ ì„±ëŠ¥ í‰ê°€
                from pycaret.regression import predict_model, pull
                predictions = predict_model(final_model, verbose=False)
                metrics = pull()
                
                # ë©”íŠ¸ë¦­ ì¶”ì¶œ
                model_metrics = {}
                if metrics is not None and not metrics.empty:
                    if 'MAE' in metrics.columns:
                        model_metrics['MAE'] = float(metrics['MAE'].iloc[-1])
                    if 'MSE' in metrics.columns:
                        model_metrics['MSE'] = float(metrics['MSE'].iloc[-1])
                    if 'RMSE' in metrics.columns:
                        model_metrics['RMSE'] = float(metrics['RMSE'].iloc[-1])
                    if 'R2' in metrics.columns:
                        model_metrics['R2'] = float(metrics['R2'].iloc[-1])
                    if 'RMSLE' in metrics.columns:
                        model_metrics['RMSLE'] = float(metrics['RMSLE'].iloc[-1])
                    if 'MAPE' in metrics.columns:
                        model_metrics['MAPE'] = float(metrics['MAPE'].iloc[-1])
            except:
                model_metrics = {}
            
        except Exception as e:
            raise RuntimeError(f"Model training failed: {str(e)}")
        finally:
            # ì¶œë ¥ ë³µì›
            sys.stdout = old_stdout
            sys.stderr = old_stderr
        
        return {
            'message': f'Model {model_name} trained successfully',
            'model_type': type(self.current_model).__name__,
            'model_name': model_name,
            'metrics': model_metrics if model_metrics else None
        }
    
    def get_model_evaluation(self) -> Dict[str, Any]:
        """í˜„ì¬ ëª¨ë¸ì˜ í‰ê°€ ê²°ê³¼ ë°˜í™˜"""
        
        if self.current_model is None:
            if self.model_results and self.model_results['recommended_model']:
                self.current_model = self.model_results['recommended_model']
            else:
                raise RuntimeError("No trained model available")
        
        old_stdout = sys.stdout
        old_stderr = sys.stderr
        
        try:
            # ì¶œë ¥ ì–µì œ
            sys.stdout = io.StringIO()
            sys.stderr = io.StringIO()
            
            # ëª¨ë¸ í‰ê°€
            evaluate_model(self.current_model)
            evaluation_results = pull()
            
        except Exception as e:
            # í‰ê°€ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì •ë³´ë§Œ ë°˜í™˜
            evaluation_results = None
            warnings.warn(f"Model evaluation failed: {str(e)}")
        finally:
            # ì¶œë ¥ ë³µì›
            sys.stdout = old_stdout
            sys.stderr = old_stderr
        
        return {
            'message': 'Model evaluation completed',
            'model_type': type(self.current_model).__name__,
            'evaluation_available': evaluation_results is not None,
            'evaluation_data': evaluation_results.to_dict() if evaluation_results is not None else None
        }
    
    def predict_with_model(self, prediction_data: Optional[pd.DataFrame] = None) -> Dict[str, Any]:
        """ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ ìˆ˜í–‰"""
        
        if self.current_model is None:
            raise RuntimeError("No trained model available for prediction")
        
        if prediction_data is None:
            # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì˜ˆì¸¡
            try:
                old_stdout = sys.stdout
                sys.stdout = io.StringIO()
                
                predictions = predict_model(self.current_model)
                prediction_results = pull()
                
            except Exception as e:
                raise RuntimeError(f"Prediction failed: {str(e)}")
            finally:
                sys.stdout = old_stdout
        else:
            # ì‚¬ìš©ì ì œê³µ ë°ì´í„°ë¡œ ì˜ˆì¸¡
            try:
                old_stdout = sys.stdout
                old_stderr = sys.stderr
                sys.stdout = io.StringIO()
                sys.stderr = io.StringIO()
                
                # PyCaretì˜ TransformerWrapperë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€í™˜ íŒŒì´í”„ë¼ì¸ ê°€ì ¸ì˜¤ê¸°
                try:
                    # get_configë¥¼ ì‚¬ìš©í•˜ì—¬ í˜„ì¬ ì‹¤í—˜ì˜ ë³€í™˜ íŒŒì´í”„ë¼ì¸ ê°€ì ¸ì˜¤ê¸°
                    X_train = get_config('X_train')
                    
                    # í•™ìŠµ ì‹œ ì‚¬ìš©ëœ feature ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
                    if hasattr(X_train, 'columns'):
                        expected_features = X_train.columns.tolist()
                    else:
                        expected_features = None
                    
                    # prediction_dataì˜ ì»¬ëŸ¼ì„ í•™ìŠµ ì‹œ ì‚¬ìš©ëœ featureì— ë§ê²Œ ì¡°ì •
                    if expected_features:
                        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ê³  ìˆœì„œ ë§ì¶”ê¸°
                        available_cols = [col for col in expected_features if col in prediction_data.columns]
                        prediction_data_aligned = prediction_data[available_cols].copy()
                        
                        # ëˆ„ë½ëœ ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ 0ìœ¼ë¡œ ì±„ìš°ê¸° (polynomial features ë“±)
                        for col in expected_features:
                            if col not in prediction_data_aligned.columns:
                                prediction_data_aligned[col] = 0
                        
                        # ì»¬ëŸ¼ ìˆœì„œ ë§ì¶”ê¸°
                        prediction_data_aligned = prediction_data_aligned[expected_features]
                    else:
                        prediction_data_aligned = prediction_data
                    
                    predictions = predict_model(self.current_model, data=prediction_data_aligned)
                    
                except Exception as align_error:
                    # ì •ë ¬ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°ì´í„°ë¡œ ì˜ˆì¸¡ ì‹œë„
                    warnings.warn(f"Feature alignment failed: {str(align_error)}. Trying with original data.")
                    predictions = predict_model(self.current_model, data=prediction_data)
                
            except Exception as e:
                raise RuntimeError(f"Prediction with custom data failed: {str(e)}")
            finally:
                sys.stdout = old_stdout
                sys.stderr = old_stderr
            
            prediction_results = None
        
        return {
            'message': 'Prediction completed successfully',
            'predictions_available': predictions is not None,
            'prediction_count': len(predictions) if predictions is not None else 0,
            'predictions': predictions.to_dict(orient='records') if predictions is not None else None,
            'evaluation_metrics': prediction_results.to_dict() if prediction_results is not None else None
        }
    
    def get_modeling_status(self) -> Dict[str, Any]:
        """í˜„ì¬ ëª¨ë¸ë§ ìƒíƒœ ë°˜í™˜"""
        return {
            'pycaret_available': self.check_pycaret_availability(),
            'environment_setup': self.is_setup_complete,
            'model_trained': self.is_model_trained_individually,  # ê°œë³„ í•™ìŠµ ì—¬ë¶€ë¡œ ë³€ê²½
            'models_compared': self.model_results is not None,
            'data_loaded': data_service.current_data is not None,
            'current_model_type': type(self.current_model).__name__ if self.current_model else None,
            'has_model': self.current_model is not None  # ëª¨ë¸ ì¡´ì¬ ì—¬ë¶€
        }
    
    def clear_models(self) -> Dict[str, Any]:
        """ëª¨ë“  ëª¨ë¸ ë° ì‹¤í—˜ ì´ˆê¸°í™”"""
        self.current_experiment = None
        self.current_model = None
        self.model_results = None
        self.is_setup_complete = False
        self.is_model_trained_individually = False  # ê°œë³„ í•™ìŠµ ìƒíƒœë„ ì´ˆê¸°í™”
        self.baseup_feature_importance = None
        self.performance_feature_importance = None
        self.current_feature_importance = None
        
        return {
            'message': 'All models and experiments cleared successfully'
        }
    
    def _capture_feature_importance(self, model) -> List[Dict[str, Any]]:
        """ëª¨ë¸ì˜ feature importanceë¥¼ ìº¡ì²˜í•˜ëŠ” ë‚´ë¶€ ë©”ì„œë“œ"""
        importance_list = []
        print(f"DEBUG: _capture_feature_importance called with model type: {type(model).__name__}")
        
        try:
            # ë°©ë²• 1: PyCaretì˜ interpret_model ì‹œë„ (ê¸°ë³¸ì ìœ¼ë¡œ feature_importance ì‚¬ìš©)
            old_stdout = sys.stdout
            sys.stdout = io.StringIO()
            
            try:
                # matplotlib backendë¥¼ non-interactiveë¡œ ì„¤ì •í•˜ì—¬ plot ì°½ì´ ëœ¨ì§€ ì•Šë„ë¡ í•¨
                import matplotlib
                matplotlib.use('Agg')  # Non-interactive backend
                
                from pycaret.regression import interpret_model
                # PyCaretì˜ interpret_modelì„ ì‚¬ìš©í•˜ì—¬ feature importance ì¶”ì¶œ
                interpret_model(model, plot='feature', save=False)
                
                # PyCaret ë‚´ë¶€ì—ì„œ feature importance ê°€ì ¸ì˜¤ê¸°
                from pycaret.regression import get_config
                X_train = get_config('X_train')
                
                # ëª¨ë¸ íƒ€ì…ì— ë”°ë¥¸ feature importance ì¶”ì¶œ
                if hasattr(model, 'feature_importances_'):
                    # Tree-based ëª¨ë¸ (RF, GBM, XGBoost ë“±)
                    importances = model.feature_importances_
                    feature_names = X_train.columns.tolist()
                    
                    for i, importance in enumerate(importances):
                        importance_list.append({
                            'feature': feature_names[i],
                            'importance': float(importance),
                            'rank': 0  # ë‚˜ì¤‘ì— ì •ë ¬ í›„ ë­í¬ ë¶€ì—¬
                        })
                        
                elif hasattr(model, 'coef_'):
                    # Linear ëª¨ë¸ (LR, Ridge, Lasso ë“±)
                    coefs = model.coef_
                    feature_names = X_train.columns.tolist()
                    
                    # ì ˆëŒ€ê°’ìœ¼ë¡œ ì¤‘ìš”ë„ ê³„ì‚°
                    for i, coef in enumerate(coefs):
                        importance_list.append({
                            'feature': feature_names[i],
                            'importance': abs(float(coef)),
                            'rank': 0
                        })
                
            except Exception as e1:
                # interpret_model often fails with PyCaret pipelines, this is expected
                print(f"DEBUG: Method 1 (interpret_model) failed: {str(e1)}")
                pass  # Silently continue to next method
                
                # ë°©ë²• 2: PyCaretì˜ plot_model ì‹œë„
                try:
                    from pycaret.regression import plot_model
                    plot_model(model, plot='feature', save=False)
                    
                    # ì—¬ê¸°ì„œë„ feature importance ì¶”ì¶œ ì‹œë„
                    from pycaret.regression import get_config
                    X_train = get_config('X_train')
                    
                    if hasattr(model, 'feature_importances_'):
                        importances = model.feature_importances_
                        feature_names = X_train.columns.tolist()
                        
                        for i, importance in enumerate(importances):
                            importance_list.append({
                                'feature': feature_names[i],
                                'importance': float(importance),
                                'rank': 0
                            })
                            
                except Exception as e2:
                    # plot_model also often fails with pipelines, expected
                    print(f"DEBUG: Method 2 (plot_model) failed: {str(e2)}")
                    pass
                    
                    # ë°©ë²• 3: ì§ì ‘ ëª¨ë¸ ì†ì„± ì ‘ê·¼
                    try:
                        from pycaret.regression import get_config
                        X_train = get_config('X_train')
                        feature_names = X_train.columns.tolist()
                        
                        # Pipelineì—ì„œ ì‹¤ì œ ëª¨ë¸ ì¶”ì¶œ
                        actual_model = model
                        if hasattr(model, 'steps'):
                            # Pipelineì¸ ê²½ìš° - ë§ˆì§€ë§‰ ë‹¨ê³„ê°€ ì‹¤ì œ ëª¨ë¸
                            actual_model = model.steps[-1][1] if model.steps else model
                            print(f"DEBUG: Extracted model from pipeline: {type(actual_model).__name__}")
                        
                        # ì¤‘ì²©ëœ Pipeline ì²˜ë¦¬
                        if hasattr(actual_model, 'steps'):
                            actual_model = actual_model.steps[-1][1] if actual_model.steps else actual_model
                            print(f"DEBUG: Extracted model from nested pipeline: {type(actual_model).__name__}")
                        
                        if hasattr(actual_model, 'feature_importances_'):
                            importances = actual_model.feature_importances_
                            print(f"DEBUG: Found feature_importances_ with {len(importances)} features")
                            for i, importance in enumerate(importances):
                                if i < len(feature_names):
                                    importance_list.append({
                                        'feature': feature_names[i],
                                        'importance': float(importance),
                                        'rank': 0
                                    })
                        elif hasattr(actual_model, 'coef_'):
                            coefs = actual_model.coef_
                            if len(coefs.shape) > 1:
                                coefs = coefs[0]
                            print(f"DEBUG: Found coef_ with {len(coefs)} coefficients")
                            for i, coef in enumerate(coefs):
                                if i < len(feature_names):
                                    importance_list.append({
                                        'feature': feature_names[i],
                                        'importance': abs(float(coef)),
                                        'rank': 0
                                    })
                                    
                    except Exception as e3:
                        # Direct access might fail too, continue to fallback
                        print(f"DEBUG: Method 3 (direct access) failed: {str(e3)}")
                        pass
                        
                        # ì‹¤ì œ ëª¨ë¸ ì†ì„±ì—ì„œ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
                        print("WARNING: Could not extract feature importance from model")
                        pass
                            
        finally:
            sys.stdout = old_stdout
        
        # ì¤‘ìš”ë„ë¡œ ì •ë ¬í•˜ê³  ë­í¬ ë¶€ì—¬
        if importance_list:
            importance_list.sort(key=lambda x: x['importance'], reverse=True)
            for i, item in enumerate(importance_list):
                item['rank'] = i + 1
                
            logging.info(f"Captured {len(importance_list)} feature importances")
            
        return importance_list
    
    def get_feature_importance(self, target: str = None) -> List[Dict[str, Any]]:
        """ì €ì¥ëœ feature importance ë°˜í™˜"""
        if target == 'wage_increase_bu_sbl' or target == 'baseup':
            return self.baseup_feature_importance or []
        elif target == 'wage_increase_mi_sbl' or target == 'performance':
            return self.performance_feature_importance or []
        else:
            return self.current_feature_importance or []

    def save_models(self):
        """í•™ìŠµëœ ëª¨ë¸ì„ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
            if not os.path.exists(self.model_dir):
                os.makedirs(self.model_dir)
                print(f"ğŸ“ Created model directory: {self.model_dir}")
            
            # Base-up ëª¨ë¸ ì €ì¥
            if self.baseup_model is not None:
                print(f"   - Saving baseup feature importance: {len(self.baseup_feature_importance) if self.baseup_feature_importance else 0} features")
                with open(self.baseup_model_path, 'wb') as f:
                    pickle.dump({
                        'model': self.baseup_model,
                        'feature_importance': self.baseup_feature_importance,
                        'target': 'wage_increase_bu_sbl'
                    }, f)
                print(f"ğŸ’¾ Base-up model saved to {self.baseup_model_path}")
            
            # Performance ëª¨ë¸ ì €ì¥
            if self.performance_model is not None:
                print(f"   - Saving performance feature importance: {len(self.performance_feature_importance) if self.performance_feature_importance else 0} features")
                with open(self.performance_model_path, 'wb') as f:
                    pickle.dump({
                        'model': self.performance_model,
                        'feature_importance': self.performance_feature_importance,
                        'target': 'wage_increase_mi_sbl'
                    }, f)
                print(f"ğŸ’¾ Performance model saved to {self.performance_model_path}")
            
            # Current modelë„ ì €ì¥ (í˜„ì¬ í™œì„± ëª¨ë¸)
            if self.current_model is not None:
                current_model_path = os.path.join(self.model_dir, "current_model.pkl")
                with open(current_model_path, 'wb') as f:
                    pickle.dump({
                        'model': self.current_model,
                        'feature_importance': self.current_feature_importance,
                        'target': self.current_target
                    }, f)
                print(f"ğŸ’¾ Current model saved to {current_model_path}")
            
            return {
                "message": "Models saved successfully",
                "baseup_saved": self.baseup_model is not None,
                "performance_saved": self.performance_model is not None,
                "current_saved": self.current_model is not None
            }
            
        except Exception as e:
            print(f"âŒ Error saving models: {str(e)}")
            return {
                "error": f"Failed to save models: {str(e)}"
            }
    
    def load_saved_models(self):
        """ì €ì¥ëœ ëª¨ë¸ì„ íŒŒì¼ì—ì„œ ë¡œë“œ"""
        try:
            models_loaded = []
            
            # Base-up ëª¨ë¸ ë¡œë“œ
            if os.path.exists(self.baseup_model_path):
                with open(self.baseup_model_path, 'rb') as f:
                    data = pickle.load(f)
                    self.baseup_model = data['model']
                    self.baseup_feature_importance = data.get('feature_importance', [])
                    models_loaded.append('baseup')
                print(f"âœ… Base-up model loaded from {self.baseup_model_path}")
                print(f"   - Feature importance: {len(self.baseup_feature_importance) if self.baseup_feature_importance else 0} features")
            
            # Performance ëª¨ë¸ ë¡œë“œ
            if os.path.exists(self.performance_model_path):
                with open(self.performance_model_path, 'rb') as f:
                    data = pickle.load(f)
                    self.performance_model = data['model']
                    self.performance_feature_importance = data.get('feature_importance', [])
                    models_loaded.append('performance')
                print(f"âœ… Performance model loaded from {self.performance_model_path}")
                print(f"   - Feature importance: {len(self.performance_feature_importance) if self.performance_feature_importance else 0} features")
            
            # Current model ë¡œë“œ
            current_model_path = os.path.join(self.model_dir, "current_model.pkl")
            if os.path.exists(current_model_path):
                with open(current_model_path, 'rb') as f:
                    data = pickle.load(f)
                    self.current_model = data['model']
                    self.current_feature_importance = data.get('feature_importance', [])
                    self.current_target = data.get('target')
                    models_loaded.append('current')
                print(f"âœ… Current model loaded from {current_model_path}")
            
            # ë¡œë“œëœ ëª¨ë¸ì´ ìˆìœ¼ë©´ ì„¤ì • ì™„ë£Œ í”Œë˜ê·¸ ì„¤ì •
            if models_loaded:
                self.is_setup_complete = True
                self.is_model_trained_individually = True
                print(f"ğŸš€ Successfully loaded {len(models_loaded)} model(s): {', '.join(models_loaded)}")
            else:
                print("â„¹ï¸ No saved models found. Please train models first.")
            
            return {
                "message": f"Loaded {len(models_loaded)} model(s)",
                "models_loaded": models_loaded,
                "ready": len(models_loaded) > 0
            }
            
        except Exception as e:
            print(f"âš ï¸ Error loading models: {str(e)}")
            print("â„¹ï¸ Models will need to be retrained.")
            return {
                "error": f"Failed to load models: {str(e)}",
                "models_loaded": [],
                "ready": False
            }

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
modeling_service = ModelingService()