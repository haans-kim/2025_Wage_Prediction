from fastapi import APIRouter, HTTPException, Query
from typing import Dict, Any, Optional, List
from pydantic import BaseModel
from app.services.modeling_service import modeling_service

router = APIRouter()

class ModelingSetupRequest(BaseModel):
    target_column: Optional[str] = None  # ìë™ ê°ì§€ ê°€ëŠ¥
    train_size: Optional[float] = None
    session_id: int = 42  # ê³ ì •ëœ ì‹œë“œê°’ ì‚¬ìš©

class ModelTrainingRequest(BaseModel):
    model_name: str
    tune_hyperparameters: bool = True

@router.post("/setup")
async def setup_modeling(request: ModelingSetupRequest) -> Dict[str, Any]:
    """
    PyCaret ëª¨ë¸ë§ í™˜ê²½ ì„¤ì •
    """
    try:
        # PyCaret ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        if not modeling_service.check_pycaret_availability():
            raise HTTPException(
                status_code=500, 
                detail="PyCaret is not installed. Please install it with: pip install pycaret"
            )
        
        # target_columnì´ ì—†ìœ¼ë©´ ìë™ ê°ì§€
        target_column = request.target_column
        if target_column is None:
            from app.services.data_service import data_service
            model_config = data_service.get_model_config()
            target_column = model_config.get('target_column')
            if target_column is None:
                # ë§ˆì§€ë§‰ ì»¬ëŸ¼ ì‚¬ìš©
                if data_service.current_data is not None:
                    target_column = data_service.current_data.columns[-1]
        
        # í™˜ê²½ ì„¤ì • ì‹¤í–‰
        result = modeling_service.setup_pycaret_environment(
            target_column=target_column,
            train_size=request.train_size,
            session_id=request.session_id
        )
        
        return {
            **result,
            "setup_request": {
                "target_column": target_column,
                "train_size": request.train_size,
                "session_id": request.session_id
            }
        }
        
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except RuntimeError as e:
        raise HTTPException(status_code=500, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Modeling setup failed: {str(e)}")

@router.post("/compare")
async def compare_models(n_select: int = Query(default=3, ge=1, le=10)) -> Dict[str, Any]:
    """
    ì—¬ëŸ¬ ML ëª¨ë¸ ë¹„êµ (ë°ì´í„° í¬ê¸°ì— ì ì‘ì )
    """
    try:
        result = modeling_service.compare_models_adaptive(n_select=n_select)
        
        # ëª¨ë¸ ë¹„êµ ì™„ë£Œ í›„ ExplainerDashboard ìºì‹œ í´ë¦¬ì–´
        try:
            from app.services.explainer_dashboard_service import explainer_dashboard_service
            from app.services.analysis_service import analysis_service
            
            # ê¸°ì¡´ ExplainerDashboard ì¤‘ì§€ (ìƒˆë¡œìš´ ëª¨ë¸ë¡œ ì¬ìƒì„± í•„ìš”)
            if explainer_dashboard_service.is_running:
                explainer_dashboard_service.stop_dashboard()
                print("ğŸ”„ Stopped ExplainerDashboard for model comparison update")
            
            # Feature importance ìºì‹œ í´ë¦¬ì–´
            analysis_service._importance_cache.clear()
            analysis_service._shap_cache.clear()
            print("ğŸ§¹ Cleared analysis caches after model comparison")
            
        except Exception as dashboard_error:
            print(f"âš ï¸ ExplainerDashboard update failed: {dashboard_error}")
        
        return {
            **result,
            "recommendation": "Use the recommended model for best performance, or choose from the best models list"
        }
        
    except RuntimeError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Model comparison failed: {str(e)}")

@router.post("/train")
async def train_specific_model(request: ModelTrainingRequest) -> Dict[str, Any]:
    """
    íŠ¹ì • ëª¨ë¸ í•™ìŠµ ë° íŠœë‹
    """
    try:
        result = modeling_service.train_specific_model(request.model_name)
        
        # ëª¨ë¸ í•™ìŠµ ì™„ë£Œ í›„ ExplainerDashboard ì¬ìƒì„±
        try:
            from app.services.explainer_dashboard_service import explainer_dashboard_service
            
            # ê¸°ì¡´ ExplainerDashboard ì¤‘ì§€
            if explainer_dashboard_service.is_running:
                explainer_dashboard_service.stop_dashboard()
                print("ğŸ”„ Stopped existing ExplainerDashboard for model update")
            
            # Feature importance ìºì‹œ í´ë¦¬ì–´ (ìƒˆë¡œìš´ ëª¨ë¸ ë°˜ì˜)
            from app.services.analysis_service import analysis_service
            analysis_service._importance_cache.clear()
            analysis_service._shap_cache.clear()
            print("ğŸ§¹ Cleared analysis caches for new model")
            
            print("âœ… ExplainerDashboard will be recreated on next request with new model data")
            
        except Exception as dashboard_error:
            print(f"âš ï¸ ExplainerDashboard update failed: {dashboard_error}")
            # Dashboard ì˜¤ë¥˜ê°€ ìˆì–´ë„ ëª¨ë¸ í•™ìŠµ ê²°ê³¼ëŠ” ë°˜í™˜
        
        return {
            **result,
            "training_options": {
                "model_name": request.model_name,
                "hyperparameter_tuning": request.tune_hyperparameters
            }
        }
        
    except RuntimeError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Model training failed: {str(e)}")

@router.get("/evaluate")
async def evaluate_current_model() -> Dict[str, Any]:
    """
    í˜„ì¬ í•™ìŠµëœ ëª¨ë¸ì˜ ì„±ëŠ¥ í‰ê°€
    """
    try:
        result = modeling_service.get_model_evaluation()
        
        return result
        
    except RuntimeError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Model evaluation failed: {str(e)}")

@router.post("/predict")
async def predict_with_model() -> Dict[str, Any]:
    """
    í˜„ì¬ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡
    """
    try:
        result = modeling_service.predict_with_model()
        
        return result
        
    except RuntimeError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Prediction failed: {str(e)}")

@router.get("/available-models")
async def get_available_models() -> Dict[str, Any]:
    """
    í˜„ì¬ ë°ì´í„°ì— ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ë°˜í™˜
    """
    try:
        from app.services.data_service import data_service
        
        if data_service.current_data is None:
            raise HTTPException(status_code=404, detail="No data loaded")
        
        data_size = len(data_service.current_data)
        optimal_settings = modeling_service.get_optimal_settings(data_size)
        
        model_descriptions = {
            'lr': 'Linear Regression - ì„ í˜• íšŒê·€',
            'ridge': 'Ridge Regression - ë¦¿ì§€ íšŒê·€',
            'lasso': 'Lasso Regression - ë¼ì˜ íšŒê·€',
            'en': 'Elastic Net - ì—˜ë¼ìŠ¤í‹±ë„·',
            'dt': 'Decision Tree - ì˜ì‚¬ê²°ì •íŠ¸ë¦¬',
            'rf': 'Random Forest - ëœë¤í¬ë ˆìŠ¤íŠ¸',
            'gbr': 'Gradient Boosting - ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…',
            'xgboost': 'XGBoost - ìµìŠ¤íŠ¸ë¦¼ ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…',
            'lightgbm': 'LightGBM - ë¼ì´íŠ¸ ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…'
        }
        
        available_models = []
        for model in optimal_settings['models']:
            available_models.append({
                'code': model,
                'name': model_descriptions.get(model, model),
                'recommended': model in optimal_settings['models'][:3]
            })
        
        return {
            'message': 'Available models retrieved successfully',
            'data_size': data_size,
            'data_size_category': 'small' if data_size < 30 else 'medium' if data_size < 100 else 'large',
            'available_models': available_models,
            'optimal_settings': {
                'train_size': optimal_settings['train_size'],
                'cv_folds': optimal_settings['cv_folds'],
                'preprocessing_enabled': {
                    'normalization': optimal_settings['normalize'],
                    'transformation': optimal_settings['transformation'],
                    'outlier_removal': optimal_settings['remove_outliers'],
                    'feature_selection': optimal_settings['feature_selection']
                }
            }
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get available models: {str(e)}")

@router.get("/status")
async def get_modeling_status() -> Dict[str, Any]:
    """
    ëª¨ë¸ë§ ì§„í–‰ ìƒí™© ë° ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
    """
    try:
        status = modeling_service.get_modeling_status()
        
        return {
            **status,
            "system_info": {
                "pycaret_installation_command": "pip install pycaret",
                "supported_tasks": ["regression"],
                "adaptive_modeling": True
            }
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get modeling status: {str(e)}")

@router.delete("/clear")
async def clear_models() -> Dict[str, Any]:
    """
    ëª¨ë“  ëª¨ë¸ ë° ì‹¤í—˜ ì´ˆê¸°í™”
    """
    try:
        result = modeling_service.clear_models()
        
        return result
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to clear models: {str(e)}")

@router.get("/recommendations")
async def get_modeling_recommendations() -> Dict[str, Any]:
    """
    í˜„ì¬ ë°ì´í„°ì— ëŒ€í•œ ëª¨ë¸ë§ ê¶Œê³ ì‚¬í•­
    """
    try:
        from app.services.data_service import data_service
        
        if data_service.current_data is None:
            raise HTTPException(status_code=404, detail="No data loaded")
        
        data_size = len(data_service.current_data)
        feature_count = len(data_service.current_data.columns) - 1  # target ì œì™¸
        
        recommendations = []
        
        if data_size < 30:
            recommendations.extend([
                "ë°ì´í„°ê°€ ì ìœ¼ë¯€ë¡œ ê°„ë‹¨í•œ ëª¨ë¸(ì„ í˜•íšŒê·€, ì˜ì‚¬ê²°ì •íŠ¸ë¦¬) ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.",
                "êµì°¨ ê²€ì¦ í´ë“œ ìˆ˜ë¥¼ 3ê°œë¡œ ì œí•œí•©ë‹ˆë‹¤.",
                "ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•´ ë³µì¡í•œ ì „ì²˜ë¦¬ëŠ” ìƒëµí•©ë‹ˆë‹¤."
            ])
        elif data_size < 100:
            recommendations.extend([
                "ì¤‘ê°„ í¬ê¸° ë°ì´í„°ë¡œ ì•™ìƒë¸” ëª¨ë¸(ëœë¤í¬ë ˆìŠ¤íŠ¸, ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…) ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.",
                "ê¸°ë³¸ì ì¸ ì „ì²˜ë¦¬(ì •ê·œí™”, ì´ìƒì¹˜ ì œê±°)ë¥¼ ì ìš©í•©ë‹ˆë‹¤.",
                "íŠ¹ì„± ì„ íƒì„ í†µí•´ ëª¨ë¸ ì„±ëŠ¥ì„ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            ])
        else:
            recommendations.extend([
                "ì¶©ë¶„í•œ ë°ì´í„°ë¡œ ê³ ê¸‰ ëª¨ë¸(XGBoost, LightGBM) ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.",
                "ì „ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì„ ì ìš©í•˜ì—¬ ìµœì  ì„±ëŠ¥ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.",
                "í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ í†µí•´ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            ])
        
        if feature_count > data_size:
            recommendations.append("í”¼ì²˜ ìˆ˜ê°€ ë°ì´í„° ìˆ˜ë³´ë‹¤ ë§ìœ¼ë¯€ë¡œ íŠ¹ì„± ì„ íƒì´ í•„ìˆ˜ì…ë‹ˆë‹¤.")
        
        return {
            'message': 'Modeling recommendations generated',
            'data_analysis': {
                'data_size': data_size,
                'feature_count': feature_count,
                'data_to_feature_ratio': round(data_size / feature_count, 2) if feature_count > 0 else 0
            },
            'recommendations': recommendations,
            'next_steps': [
                "1. íƒ€ê²Ÿ ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ì—¬ ëª¨ë¸ë§ í™˜ê²½ì„ ì„¤ì •í•˜ì„¸ìš”.",
                "2. ì—¬ëŸ¬ ëª¨ë¸ì„ ë¹„êµí•˜ì—¬ ìµœì  ëª¨ë¸ì„ ì°¾ìœ¼ì„¸ìš”.",
                "3. ì„ íƒëœ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ì„±ëŠ¥ì„ í‰ê°€í•˜ì„¸ìš”.",
                "4. ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì„¸ìš”."
            ]
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to generate recommendations: {str(e)}")