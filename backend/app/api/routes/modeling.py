from fastapi import APIRouter, HTTPException, Query
from typing import Dict, Any, Optional, List
from pydantic import BaseModel
from app.services.modeling_service import modeling_service

router = APIRouter()

class ModelingSetupRequest(BaseModel):
    target_column: str
    train_size: Optional[float] = None
    session_id: int = 123

class ModelTrainingRequest(BaseModel):
    model_name: str
    tune_hyperparameters: bool = True

class FeatureAdjustmentRequest(BaseModel):
    target: str  # 'baseup' or 'performance'
    feature_values: Dict[str, float]  # Feature name to adjusted value mapping
    use_baseline: bool = True  # Whether to use baseline values for non-adjusted features

@router.post("/setup")
async def setup_modeling(request: ModelingSetupRequest) -> Dict[str, Any]:
    """
    PyCaret ëª¨ë¸ë§ í™˜ê²½ ì„¤ì •
    """
    print(f"\nğŸ” Setup Request: target={request.target_column}, train_size={request.train_size}, session_id={request.session_id}")
    try:
        # PyCaret ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        if not modeling_service.check_pycaret_availability():
            raise HTTPException(
                status_code=500, 
                detail="PyCaret is not installed. Please install it with: pip install pycaret"
            )
        
        # í™˜ê²½ ì„¤ì • ì‹¤í–‰
        result = modeling_service.setup_pycaret_environment(
            target_column=request.target_column,
            train_size=request.train_size,
            session_id=request.session_id
        )
        
        return {
            **result,
            "setup_request": {
                "target_column": request.target_column,
                "train_size": request.train_size,
                "session_id": request.session_id
            }
        }
        
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except RuntimeError as e:
        raise HTTPException(status_code=500, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Modeling setup failed: {str(e)}")

@router.post("/compare")
async def compare_models(n_select: int = Query(default=3, ge=1, le=10)) -> Dict[str, Any]:
    """
    ì—¬ëŸ¬ ML ëª¨ë¸ ë¹„êµ (ë°ì´í„° í¬ê¸°ì— ì ì‘ì )
    """
    print(f"\nğŸ” Compare Models: n_select={n_select}")
    try:
        result = modeling_service.compare_models_adaptive(n_select=n_select)
        
        # ìƒìœ„ 3ê°œ ëª¨ë¸ ì¶œë ¥
        if 'comparison_results' in result and result['comparison_results']:
            print(f"ğŸ† Top 3 Models:")
            for i, model in enumerate(result['comparison_results'][:3], 1):
                print(f"   {i}. {model.get('Model', 'N/A')}: R2={model.get('R2', 'N/A')}")
        
        return {
            **result,
            "recommendation": "Use the recommended model for best performance, or choose from the best models list"
        }
        
    except RuntimeError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Model comparison failed: {str(e)}")

@router.post("/train")
async def train_specific_model(request: ModelTrainingRequest) -> Dict[str, Any]:
    """
    íŠ¹ì • ëª¨ë¸ í•™ìŠµ ë° íŠœë‹
    """
    try:
        result = modeling_service.train_specific_model(request.model_name)
        
        return {
            **result,
            "training_options": {
                "model_name": request.model_name,
                "hyperparameter_tuning": request.tune_hyperparameters
            }
        }
        
    except RuntimeError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Model training failed: {str(e)}")

@router.get("/evaluate")
async def evaluate_current_model() -> Dict[str, Any]:
    """
    í˜„ì¬ í•™ìŠµëœ ëª¨ë¸ì˜ ì„±ëŠ¥ í‰ê°€
    """
    try:
        result = modeling_service.get_model_evaluation()
        
        return result
        
    except RuntimeError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Model evaluation failed: {str(e)}")

@router.post("/predict")
async def predict_with_model() -> Dict[str, Any]:
    """
    í˜„ì¬ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡
    """
    try:
        result = modeling_service.predict_with_model()
        
        return result
        
    except RuntimeError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Prediction failed: {str(e)}")

@router.get("/available-models")
async def get_available_models() -> Dict[str, Any]:
    """
    í˜„ì¬ ë°ì´í„°ì— ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ë°˜í™˜
    """
    try:
        from app.services.data_service import data_service
        
        if data_service.current_data is None:
            raise HTTPException(status_code=404, detail="No data loaded")
        
        data_size = len(data_service.current_data)
        optimal_settings = modeling_service.get_optimal_settings(data_size)
        
        model_descriptions = {
            'lr': 'Linear Regression - ì„ í˜• íšŒê·€',
            'ridge': 'Ridge Regression - ë¦¿ì§€ íšŒê·€',
            'lasso': 'Lasso Regression - ë¼ì˜ íšŒê·€',
            'en': 'Elastic Net - ì—˜ë¼ìŠ¤í‹±ë„·',
            'dt': 'Decision Tree - ì˜ì‚¬ê²°ì •íŠ¸ë¦¬',
            'rf': 'Random Forest - ëœë¤í¬ë ˆìŠ¤íŠ¸',
            'gbr': 'Gradient Boosting - ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…',
            'xgboost': 'XGBoost - ìµìŠ¤íŠ¸ë¦¼ ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…',
            'lightgbm': 'LightGBM - ë¼ì´íŠ¸ ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…'
        }
        
        available_models = []
        for model in optimal_settings['models']:
            available_models.append({
                'code': model,
                'name': model_descriptions.get(model, model),
                'recommended': model in optimal_settings['models'][:3]
            })
        
        return {
            'message': 'Available models retrieved successfully',
            'data_size': data_size,
            'data_size_category': 'small' if data_size < 30 else 'medium' if data_size < 100 else 'large',
            'available_models': available_models,
            'optimal_settings': {
                'train_size': optimal_settings['train_size'],
                'cv_folds': optimal_settings['cv_folds'],
                'preprocessing_enabled': {
                    'normalization': optimal_settings['normalize'],
                    'transformation': optimal_settings['transformation'],
                    'outlier_removal': optimal_settings['remove_outliers'],
                    'feature_selection': optimal_settings['feature_selection']
                }
            }
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get available models: {str(e)}")

@router.get("/status")
async def get_modeling_status() -> Dict[str, Any]:
    """
    ëª¨ë¸ë§ ì§„í–‰ ìƒí™© ë° ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
    """
    try:
        status = modeling_service.get_modeling_status()
        
        return {
            **status,
            "system_info": {
                "pycaret_installation_command": "pip install pycaret",
                "supported_tasks": ["regression"],
                "adaptive_modeling": True
            }
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get modeling status: {str(e)}")

@router.delete("/clear")
async def clear_models() -> Dict[str, Any]:
    """
    ëª¨ë“  ëª¨ë¸ ë° ì‹¤í—˜ ì´ˆê¸°í™”
    """
    try:
        result = modeling_service.clear_models()
        
        return result
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to clear models: {str(e)}")

@router.get("/recommendations")
async def get_modeling_recommendations() -> Dict[str, Any]:
    """
    í˜„ì¬ ë°ì´í„°ì— ëŒ€í•œ ëª¨ë¸ë§ ê¶Œê³ ì‚¬í•­
    """
    try:
        from app.services.data_service import data_service
        
        if data_service.current_data is None:
            raise HTTPException(status_code=404, detail="No data loaded")
        
        data_size = len(data_service.current_data)
        feature_count = len(data_service.current_data.columns) - 1  # target ì œì™¸
        
        recommendations = []
        
        if data_size < 30:
            recommendations.extend([
                "ë°ì´í„°ê°€ ì ìœ¼ë¯€ë¡œ ê°„ë‹¨í•œ ëª¨ë¸(ì„ í˜•íšŒê·€, ì˜ì‚¬ê²°ì •íŠ¸ë¦¬) ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.",
                "êµì°¨ ê²€ì¦ í´ë“œ ìˆ˜ë¥¼ 3ê°œë¡œ ì œí•œí•©ë‹ˆë‹¤.",
                "ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•´ ë³µì¡í•œ ì „ì²˜ë¦¬ëŠ” ìƒëµí•©ë‹ˆë‹¤."
            ])
        elif data_size < 100:
            recommendations.extend([
                "ì¤‘ê°„ í¬ê¸° ë°ì´í„°ë¡œ ì•™ìƒë¸” ëª¨ë¸(ëœë¤í¬ë ˆìŠ¤íŠ¸, ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…) ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.",
                "ê¸°ë³¸ì ì¸ ì „ì²˜ë¦¬(ì •ê·œí™”, ì´ìƒì¹˜ ì œê±°)ë¥¼ ì ìš©í•©ë‹ˆë‹¤.",
                "íŠ¹ì„± ì„ íƒì„ í†µí•´ ëª¨ë¸ ì„±ëŠ¥ì„ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            ])
        else:
            recommendations.extend([
                "ì¶©ë¶„í•œ ë°ì´í„°ë¡œ ê³ ê¸‰ ëª¨ë¸(XGBoost, LightGBM) ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.",
                "ì „ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì„ ì ìš©í•˜ì—¬ ìµœì  ì„±ëŠ¥ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.",
                "í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ í†µí•´ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            ])
        
        if feature_count > data_size:
            recommendations.append("í”¼ì²˜ ìˆ˜ê°€ ë°ì´í„° ìˆ˜ë³´ë‹¤ ë§ìœ¼ë¯€ë¡œ íŠ¹ì„± ì„ íƒì´ í•„ìˆ˜ì…ë‹ˆë‹¤.")
        
        return {
            'message': 'Modeling recommendations generated',
            'data_analysis': {
                'data_size': data_size,
                'feature_count': feature_count,
                'data_to_feature_ratio': round(data_size / feature_count, 2) if feature_count > 0 else 0
            },
            'recommendations': recommendations,
            'next_steps': [
                "1. íƒ€ê²Ÿ ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ì—¬ ëª¨ë¸ë§ í™˜ê²½ì„ ì„¤ì •í•˜ì„¸ìš”.",
                "2. ì—¬ëŸ¬ ëª¨ë¸ì„ ë¹„êµí•˜ì—¬ ìµœì  ëª¨ë¸ì„ ì°¾ìœ¼ì„¸ìš”.",
                "3. ì„ íƒëœ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ì„±ëŠ¥ì„ í‰ê°€í•˜ì„¸ìš”.",
                "4. ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì„¸ìš”."
            ]
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to generate recommendations: {str(e)}")

@router.get("/feature-importance/{target}")
async def get_feature_importance(
    target: str,
    top_n: int = Query(default=10, ge=1, le=50)
) -> Dict[str, Any]:
    """
    íŠ¹ì • ëª¨ë¸ì˜ feature importance ë°˜í™˜
    
    Args:
        target: 'baseup' or 'performance' or 'wage_increase_bu_sbl' or 'wage_increase_mi_sbl'
        top_n: ë°˜í™˜í•  ìƒìœ„ feature ê°œìˆ˜
    """
    try:
        # Feature importance ê°€ì ¸ì˜¤ê¸°
        importance_list = modeling_service.get_feature_importance(target)
        
        if not importance_list:
            # Feature importanceê°€ ì—†ëŠ” ê²½ìš°, ëª¨ë¸ì´ í•™ìŠµë˜ì—ˆëŠ”ì§€ í™•ì¸
            if target in ['baseup', 'wage_increase_bu_sbl']:
                if not modeling_service.baseup_model:
                    raise HTTPException(status_code=404, detail="Base-up model not trained yet")
            elif target in ['performance', 'wage_increase_mi_sbl']:
                if not modeling_service.performance_model:
                    raise HTTPException(status_code=404, detail="Performance model not trained yet")
            
            # ëª¨ë¸ì€ ìˆì§€ë§Œ feature importanceê°€ ì—†ëŠ” ê²½ìš°
            raise HTTPException(status_code=404, detail="Feature importance not available. Please retrain the model.")
        
        # ìƒìœ„ Nê°œë§Œ ë°˜í™˜
        top_features = importance_list[:top_n] if len(importance_list) > top_n else importance_list
        
        # í˜„ì¬ ë°ì´í„°ì—ì„œ baseline ê°’ ê°€ì ¸ì˜¤ê¸°
        from app.services.data_service import data_service
        baseline_values = {}
        if data_service.current_data is not None:
            for feature_info in top_features:
                feature_name = feature_info['feature']
                if feature_name in data_service.current_data.columns:
                    # ìµœê·¼ ê°’ ë˜ëŠ” í‰ê· ê°’ ì‚¬ìš©
                    baseline_values[feature_name] = float(data_service.current_data[feature_name].iloc[-1])
        
        return {
            'message': 'Feature importance retrieved successfully',
            'target': target,
            'total_features': len(importance_list),
            'top_n': top_n,
            'features': top_features,
            'baseline_values': baseline_values
        }
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get feature importance: {str(e)}")

@router.post("/predict-with-adjustments")
async def predict_with_adjustments(request: FeatureAdjustmentRequest) -> Dict[str, Any]:
    """
    ì¡°ì •ëœ feature ê°’ìœ¼ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰
    """
    try:
        from app.services.data_service import data_service
        import pandas as pd
        
        # ëª¨ë¸ ì„ íƒ
        if request.target in ['baseup', 'wage_increase_bu_sbl']:
            model = modeling_service.baseup_model
            target_name = 'Base-up'
        elif request.target in ['performance', 'wage_increase_mi_sbl']:
            model = modeling_service.performance_model
            target_name = 'Performance'
        else:
            raise HTTPException(status_code=400, detail="Invalid target. Use 'baseup' or 'performance'")
        
        if not model:
            raise HTTPException(status_code=404, detail=f"{target_name} model not trained yet")
        
        # Baseline ë°ì´í„° ì¤€ë¹„ (ìµœê·¼ ë°ì´í„° ì‚¬ìš©)
        if data_service.current_data is None:
            raise HTTPException(status_code=404, detail="No data loaded")
        
        # ìµœê·¼ ë ˆì½”ë“œë¥¼ baselineìœ¼ë¡œ ì‚¬ìš©
        baseline_data = data_service.current_data.iloc[-1:].copy()
        
        # Feature ê°’ ì¡°ì •
        for feature_name, adjusted_value in request.feature_values.items():
            if feature_name in baseline_data.columns:
                baseline_data[feature_name] = adjusted_value
            else:
                # Featureê°€ ì—†ëŠ” ê²½ìš° ê²½ê³ ë§Œ í•˜ê³  ê³„ì† ì§„í–‰
                import warnings
                warnings.warn(f"Feature '{feature_name}' not found in data")
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        try:
            # PyCaretì˜ predict_model ì‚¬ìš©
            from pycaret.regression import predict_model
            import sys
            import io
            
            old_stdout = sys.stdout
            sys.stdout = io.StringIO()
            
            # íƒ€ê²Ÿ ì»¬ëŸ¼ ì œê±° (ìˆëŠ” ê²½ìš°)
            target_cols = ['wage_increase_bu_sbl', 'wage_increase_mi_sbl']
            for col in target_cols:
                if col in baseline_data.columns:
                    baseline_data = baseline_data.drop(columns=[col])
            
            predictions = predict_model(model, data=baseline_data, verbose=False)
            sys.stdout = old_stdout
            
            # ì˜ˆì¸¡ ê²°ê³¼ ì¶”ì¶œ
            if 'prediction_label' in predictions.columns:
                predicted_value = float(predictions['prediction_label'].iloc[0])
            elif 'Label' in predictions.columns:
                predicted_value = float(predictions['Label'].iloc[0])
            else:
                # ë§ˆì§€ë§‰ ì»¬ëŸ¼ì´ ì˜ˆì¸¡ê°’ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
                predicted_value = float(predictions.iloc[0, -1])
            
            # Baseline ì˜ˆì¸¡ (ì¡°ì • ì „)
            baseline_original = data_service.current_data.iloc[-1:].copy()
            for col in target_cols:
                if col in baseline_original.columns:
                    baseline_original = baseline_original.drop(columns=[col])
            
            sys.stdout = io.StringIO()
            baseline_predictions = predict_model(model, data=baseline_original, verbose=False)
            sys.stdout = old_stdout
            
            if 'prediction_label' in baseline_predictions.columns:
                baseline_value = float(baseline_predictions['prediction_label'].iloc[0])
            elif 'Label' in baseline_predictions.columns:
                baseline_value = float(baseline_predictions['Label'].iloc[0])
            else:
                baseline_value = float(baseline_predictions.iloc[0, -1])
            
            # ë³€í™”ëŸ‰ ê³„ì‚°
            change = predicted_value - baseline_value
            change_percent = (change / baseline_value * 100) if baseline_value != 0 else 0
            
        except Exception as e:
            raise RuntimeError(f"Prediction failed: {str(e)}")
        
        return {
            'message': 'Prediction with adjustments completed successfully',
            'target': request.target,
            'target_name': target_name,
            'baseline_prediction': baseline_value,
            'adjusted_prediction': predicted_value,
            'change': change,
            'change_percent': change_percent,
            'adjusted_features': request.feature_values,
            'feature_count': len(request.feature_values)
        }
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to predict with adjustments: {str(e)}")

@router.post("/save-models")
async def save_models() -> Dict[str, Any]:
    """
    í•™ìŠµëœ ëª¨ë¸ì„ íŒŒì¼ë¡œ ì €ì¥
    """
    try:
        result = modeling_service.save_models()
        
        if 'error' in result:
            raise HTTPException(status_code=500, detail=result['error'])
        
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to save models: {str(e)}")

@router.post("/load-models")
async def load_models() -> Dict[str, Any]:
    """
    ì €ì¥ëœ ëª¨ë¸ì„ íŒŒì¼ì—ì„œ ë¡œë“œ
    """
    try:
        result = modeling_service.load_saved_models()
        
        if 'error' in result:
            raise HTTPException(status_code=500, detail=result['error'])
        
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to load models: {str(e)}")